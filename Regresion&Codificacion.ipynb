{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión y codificación de atributos binarios\n",
    "**Autor:** José A. Troyano &nbsp;&nbsp;&nbsp; **Revisor:** Beatriz Pontes   &nbsp;&nbsp;&nbsp; **Última modificación:** 17/01/2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contenido\n",
    "\n",
    "1. <a href=\"#regresor\">Entrenamiento de un regresor</a> <br>\n",
    "    1.1 <a href=\"#lineal\">Regresión lineal</a> <br>\n",
    "    1.2 <a href=\"#estimadores\">Uso de estimadores:</a> _fit_, _predict_, _cross_\\__val_\\__predict_ y _cross_\\__val_\\__score_\n",
    "2. <a href=\"#evaluacion\">Evaluación: _MAE_, _MSE_ y _R2_</a> <br>\n",
    "3. <a href=\"#val_ausentes\">Tratamiento de valores ausentes</a> <br>\n",
    "    3.1 <a href=\"#sust_media\">Sustitución por la media</a> <br>\n",
    "    3.2 <a href=\"#sust_regresor\">Sustitución usando un regresor</a><br>\n",
    "4. <a href=\"#cod_discretos\">Codificación de atributos discretos</a><br>\n",
    "    4.1 <a href=\"#tipos_atributos\">Tipos de atributos</a> <br>\n",
    "    4.2 <a href=\"#label_encoding\">Codificación _label encoding_</a><br>\n",
    "    4.3 <a href=\"#one_hot\">Codificación _one hot_</a> <br>\n",
    "    4.4 <a href=\"#mas_atributos\">Usando más atributos</a> <br>\n",
    "------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook usaremos un dataset para entrenar un regresor de Sklearn y veremos distintas formas de evaluar la calidad del regresor obtenido. Veremos, además, cómo usar un regresor para rellenar valores ausentes de un atributo numérico. Y, por último, veremos cómo codificar atributos discretos mediante valores numéricos. Esto es necesario porque muchos de los algoritmos de aprendizaje solo soportan atributos numéricos. En concreto, Sklearn solo puede manejar atributos numéricos.\n",
    "\n",
    "Empezaremos por importar todos los elementos que usaremos a lo largo del notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Regresión y evaluación\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comenzar, usaremos el dataset _concrete_, disponible en el repositorio UCI. El dataset contiene 1030 registros correspondientes a medidas de resistencia de hormigón. Los atributos se corresponden con las proporciones de la mezcla distintas muestras de hormigón y la edad (en días) de la muestra. La variable numérica a predecir es la resistencia de cada muestra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# EJERCICIO: leer el fichero 'concrete.csv' y crear el dataframe 'X' para los atributos, y la serie 'y' para la clase\n",
    "DATOS = pd.read_csv('./data/Concrete.csv')\n",
    "X = pd.DataFrame(data=DATOS.iloc[:,0:8]) # every other column\n",
    "y = pd.Series(DATOS.iloc[:,-1]) # strength"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Entrenamiento de un regresor <a name=\"regresor\"> </a>\n",
    "\n",
    "Entrenar un regresor es muy simple en Sklearn. Al igual que ocurre con un clasificador, basta con crear un objeto del estimador que queramos entrenar y ejecutar el método <code>fit</code>. En este notebook usaremos uno de los regresores más comunes: <code>LinearRegression</code>.\n",
    "\n",
    "### 1.1 Regresión Lineal <a name=\"lineal\"> </a>\n",
    "\n",
    "La Regresión Linenal es un modelo matemático usado para aproximar la relación entre una variable dependiente $y$, y las variables independientes $x_i$. El modelo se expresa con la siguiente fórmula:\n",
    "\n",
    "$$\n",
    "y \\approx \\alpha+\\beta_1x_1+\\beta_2x_2...+\\beta_nx_n\n",
    "$$\n",
    "\n",
    "Sklearn proporciona distinos métodos para realizar regresión lineal. El más simple de ellos es el de los _mínimos cuadrados_ que es el que implementa el estimador <code>LinearRegression</code>. La técnica de los mínimos cuadrados se utiliza para determinar los coeficientes de una función de regresión que minimicen la suma de los cuadrados de los errores. Para una función de regresión lineal, se trataría de minimizar esta expresión:\n",
    "\n",
    "$$\n",
    "S = \\sum (y - f(X))^2 = \\sum (y - \\alpha+\\beta_1x_1+\\beta_2x_2...+\\beta_nx_n)^2\n",
    "$$\n",
    "\n",
    "\n",
    "### 1.2 Uso de estimadores <a name=\"estimadores\"> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EJERCICIO: crear un estimador de la clase LinearRegression y entrenarlo con el dataset <X,y>\n",
    "lr_clf = LinearRegression()\n",
    "lr_clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez entrenado un regresor, podemos usarlo para predecir la clase de un conjunto de instancias con el método <code>predict</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([53.46346329, 53.73475651, 56.81258504, 67.66368153, 60.91205585,\n",
       "       26.85991563, 68.42076149, 29.92792448, 19.7781474 , 31.44208441])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EJERCICIO: predecir la salida de los primeros 10 valores de X con el regresor entrenado anteriormente\n",
    "lr_clf.predict(X[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos aplicar validación cruzada para evaluar, de la misma forma que hicimos con la clasificación. Por defecto la métrica de evaluación es <code>r2_score</code> aunque, como veremos en la siguiente sección, hay más métricas implementadas en Sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([53.31616047, 53.75523611, 61.10426739, ..., 26.69607519,\n",
       "       29.23867412, 31.7853727 ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EJERCICIO: predecir la salida de todas las instancias mediante validación cruzada y guardar las prediccciones en y_pred\n",
    "y_pred = cross_val_predict(lr_clf,X,y, cv = 10)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5274322794587907"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EJERCICIO: calcular la métrica r2_score sobre todas las instancias mediante validación cruzada\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Evaluación <a name=\"evaluacion\"> </a>\n",
    "\n",
    "En las tareas de clasificación las métricas de evaluación se basan en el número de aciertos de las predicciones. En la regresión, sin embargo, no se puede hablar de aciertos ya que las predicciones son numéricas y es muy improbable predecir exactamente el valor correcto. Lo importante para evaluar un regresor es medir la diferencia entre el valor real y el valor predicho. \n",
    "\n",
    "En esta sección tres de las métricas más populares para evaluar la calidad de los regresores:\n",
    "- MAE: _mean absolute error_\n",
    "- MSE: _mean squared error_\n",
    "- R2: coeficiente de determinación\n",
    "\n",
    "Las fórmulas para cada una de las tres métricas son:\n",
    "\n",
    "$$\n",
    "MAE = \\frac{\\sum |\\;y -f(X)\\;|}{n}\n",
    "$$\n",
    "\n",
    "$$\n",
    "MSE = \\frac{\\sum (y -f(X))^2}{n}\n",
    "$$\n",
    "\n",
    "$$\n",
    "R2 = 1 - \\frac{\\sum (y -f(X))^2}{\\sum (\\bar{y} - y)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score:  -0.2857142857142858\n",
      "MAE:  0.75\n",
      "MSE:  1.125\n"
     ]
    }
   ],
   "source": [
    "# EJERCICIO: dadas los siguientes vectores 'y_real' e 'y_pred' calcular las métricas MAE, MSE y R2\n",
    "#    y_real = [1,   0.5, 1.5, -1]\n",
    "#    y_pred = [1.5, 0,   1.5,  1]\n",
    "\n",
    "y_real = [1,   0.5, 1.5, -1]\n",
    "y_pred = [1.5, 0,   1.5,  1]\n",
    "print(\"R2 score: \", r2_score(y_real,y_pred))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(\"MAE: \" , mean_absolute_error(y_real,y_pred))\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"MSE: \", mean_squared_error(y_real,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 scoring:  0.46099404916628633\n",
      "mae scoring:  -8.92539956910218\n",
      "mse scoring:  -128.13775612964704\n"
     ]
    }
   ],
   "source": [
    "# EJERCICIO: calcular las métricas MAE, MSE y R2 mediante validación cruzada para el dataset 'concrete' y LinearRegression\n",
    "# NOTA: los scores MAE y MSE son negativos para que los valores altos se correspondan con mejores resultados\n",
    "y_pred_r2 = cross_val_score(lr_clf,X,y, scoring = 'r2', cv = 5)\n",
    "y_pred_mae = cross_val_score(lr_clf,X,y, scoring = 'neg_mean_absolute_error', cv = 5)\n",
    "y_pred_mse = cross_val_score(lr_clf,X,y, scoring = 'neg_mean_squared_error', cv = 5)\n",
    "\n",
    "print(\"r2 scoring: \", y_pred_r2.mean())\n",
    "print(\"mae scoring: \", y_pred_mae.mean())\n",
    "print(\"mse scoring: \", y_pred_mse.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tratamiento de valores ausentes <a name=\"val_ausentes\"> </a>\n",
    "\n",
    "En esta sección utilizaremos un regresor para estimar los valores ausentes de un atributo. En ocasiones esta técnica puede funcionar, pero no es una solución aplicable de forma general. Para que funcione realmente debe haber cierta redundancia entre los atributos del dataset, de esta forma podrá aprenderse cierta relación entre el atributo ausente y el resto de atributos. Usamos regresión porque el atributo con valores ausentes es numérico, si fuese un atributo discreto deberíamos usar un clasificador.\n",
    "\n",
    "Haremos las pruebas con un dataset de calificaciones de estudiantes. Cada registro contendrá cinco informaciones (el curso en el que el estudiante inició sus estudios y cuatro calificaciones parciales) y la variable a estimar es la calificación final. En total hay 95 registros, y hay dos versiones del dataset:\n",
    "- <code>class-grades.csv</code>: con los valores de todos los atributos.\n",
    "- <code>incomplete-class-grades.csv</code>: el atributo <code>Midterm</code> solo está presente en 76 de las 95 instancias.\n",
    "\n",
    "Evaluaremos tres versiones del dataset:\n",
    "- Completo\n",
    "- Incompleto en el que los valores ausentes se sustituyen por la media del atributo <code>Midterm</code>\n",
    "- Incompleto en el que los valores ausentes se sustituyen mediante un regresor sobre el resto de atributo (no sobre la clase de salida)\n",
    "\n",
    "Nos apoyaremos en la siguiente función para evaluar cada versión del dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que, dado un dataset, calcula 'X' e 'y', y evalua la predicción de 'Final' mediante validación cruzada\n",
    "def evalua(datos):\n",
    "    y = datos['Final']\n",
    "    X = datos.drop(['Final'], axis=1)\n",
    "    clasificador = LinearRegression()\n",
    "    scores = cross_val_score(clasificador, X, y, cv=10)\n",
    "    print(scores.mean())\n",
    "    \n",
    "# Es mejor cuanto más se acerca a a 1 ya que el cross_val_score usa por defecto r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: leer el fichero 'class-grades.csv' y guardarlo en el dataset 'datos_completos' \n",
    "datos_completos = pd.read_csv('./class-grades.csv')\n",
    "datos_completos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: leer el fichero 'incomplete-class-grades.csv' y guardarlo en el dataset 'datos_incompletos' \n",
    "datos_incompletos = pd.read_csv('./incomplete-class-grades.csv')\n",
    "datos_incompletos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO:evaluar el dataset con los datos completos\n",
    "evalua(datos_completos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: ¿qué ocurre cuando se intenta evaluar el dataset con datos ausentes?\n",
    "evalua(datos_incompletos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Sustitución por la media <a name=\"sust_media\"> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: realizar los siguientes pasos para evaluar la técnica de sustitución de valores ausentes mediante la media:\n",
    "#    - Hacer una copia del dataset 'datos_incompletos' en 'rellenos_con_media'\n",
    "#    - Calcular la media del atributo 'Midterm'\n",
    "#    - Sustituir los valores ausentes por la media\n",
    "#    - Evaluar el dataset resultante\n",
    "\n",
    "rellenos_con_media = datos_incompletos.copy()\n",
    "midter_mean = rellenos_con_media['Midterm'].mean()\n",
    "#rellenos_con_media.isna().any() TRUE para Midterm\n",
    "rellenos_con_media['Midterm'].fillna(midter_mean, inplace=True)\n",
    "evalua(rellenos_con_media)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Sustitución usando un regresor <a name=\"sust_regresor\"> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: realizar los siguientes pasos para entrenar un regresor que prediga 'Midterm' en función de otras columnas\n",
    "#    - Crear la lista de posibles predictores: predictores_midterm = ['Prefix', Assignment', 'Tutorial', TakeHome']\n",
    "#    - Crear 'X_train' e 'y_train' con los predictores anteriores y solo para las filas completas\n",
    "#    - Entrenar un regresor lineal a partir de 'X_train' e 'y_train'\n",
    "\n",
    "predictores_midterm = ['Prefix', 'Assignment', 'Tutorial', 'TakeHome']\n",
    "solo_completos = datos_incompletos[~np.isnan(datos_incompletos['Midterm'])].copy()\n",
    "X_train = solo_completos[predictores_midterm]\n",
    "y_train = solo_completos['Midterm']\n",
    "\n",
    "r1 = LinearRegression()\n",
    "r1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente función calculará siempre un valor para el atributo <code>Midterm</code>. Si no está definido, se apoyará en el resto de atributos y en el modelo de regresión para estimar uno:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcula_midterm(fila, modelo, columnas):\n",
    "    if np.isnan(fila['Midterm']):\n",
    "        atributos = fila[columnas]\n",
    "        return modelo.predict([atributos])[0]\n",
    "    else:\n",
    "        return fila['Midterm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: realizar los siguientes pasos para evaluar la técnica de sustitución de valores ausentes mediante regresion:\n",
    "#    - Hacer una copia del dataset 'datos_incompletos' en 'rellenos_con_regresion'\n",
    "#    - Sustituir los valores ausentes con la función calcula_midterm\n",
    "#    - Evaluar el dataset resultante\n",
    "#    - ¿Qué combinación de 'predictores_midterm' funciona mejor?\n",
    "\n",
    "rellenos_con_regresion = datos_incompletos.copy()\n",
    "rellenos_con_regresion['Midterm'] = rellenos_con_regresion.apply(calcula_midterm,axis=1,args=(r1,predictores_midterm))\n",
    "evalua(rellenos_con_regresion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Codificación de atributos discretos <a name=\"cod_discretos\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección usaremos el dataset automobile, disponible en el repositorio UCI. El dataset original tiene algunos valores ausentes, pero nosotros trabajaremos con una versión en la que se han eliminado algunas filas y columnas para que no haya ningún valor ausente. En nuestra versión, el dataset contiene 197 filas con 22 atributos que describen características de coches y un atributo numérico price que será el que usaremos para entrenar un regresor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empezaremos por leer el dataset y crear 'X' e 'y'\n",
    "datos = pd.read_csv('./automobile.csv')\n",
    "y = datos['price']\n",
    "X = datos.drop(['price'], axis=1)\n",
    "print(X.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Tipos de atributos y _baseline_ con atributos numéricos <a name=\"tipos_atributos\"> </a>\n",
    "\n",
    "En esta sección separaremos el dataframe según el tipo de atributo y evaluaremos un regresor usando solo los atributos numéricos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: crear las matrices 'X_discretos' y 'X_numericos' con los atributos discretos y numéricos, respectivamente, de 'X'\n",
    "X_discretos = X.select_dtypes(['object'])\n",
    "X_numericos = X.select_dtypes(['number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: definir una función 'evalua_dataset' que haga lo siguiente:\n",
    "#    - Reciba como parámetros X e y\n",
    "#    - Evalue mediante validación cruzada un RandomForestRegressor con n_estimators=200 y random_state=0\n",
    "#    - Devuelva el resultado de la evaluación\n",
    "\n",
    "def evalua_dataset(X,y):\n",
    "    clasificador = RandomForestRegressor(n_estimators=200, random_state=0)\n",
    "    scores = cross_val_score(clasificador, X, y, cv=10)\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST: de la función evalua_dataset\n",
    "print(evalua_dataset(X_numericos, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: mostrar la frecuencia de aparición de los valores de los atributos discretos\n",
    "columnas = X_discretos.columns\n",
    "for c in columnas:\n",
    "    print(\"Columna: \", c ,\"  \", np.unique(X_discretos[c],return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Según estos resultados nos encontramos con tres tipos de atributos discretos:\n",
    "- **Binarios**: <code>['fuel-type', 'aspiration', 'engine-location']</code>\n",
    "- **Categóricos**: <code>['make', 'body-style', 'drive-wheels', 'engine-type', 'fuel-system']</code>\n",
    "- **Ordinales**: <code>['num-of-doors', 'num-of-cylinders']</code>\n",
    "\n",
    "Los atributos ordinales se pueden codificar mediante un único atributo numérico, ya que la relación de orden se mantiene en la representación numérica. A este tipo de codificación se le denomina _label encoding_.\n",
    "\n",
    "Los categóricos, sin embargo, no se pueden codificar con un número, ya que el algoritmo de aprendizaje asumiría una relación de orden que no existe. En este caso se debe utilizar una codificación en varias columnas, el denominado _one-hot encoding_.\n",
    "\n",
    "Los binarios son realmente categóricos, pero podemos intentar codificarlos con un único atributo numérico que tome los valores $0$ y $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Codificación _label encoding_ <a name=\"label_encoding\"> </a>\n",
    "\n",
    "La codificación _label encoding_ consiste en sustituir cada valor del atributo discreto por un valor numérico. Sklearn proporciona métodos para hacerlo, pero nosostros lo haremos directamente con el método map() de Pandas ya que se trata de un proceso bastante simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: codificar mediante label encoding los atributos ordinales y los binarios\n",
    "#    - Almacenar los nuevos atributos en una nueva matriz 'X_label'\n",
    "#    - Elegir un valor numérco apropiado para cada valor discreto\n",
    "#    - Se puede aplicar el método map() de las Series para realizar la correspondencia\n",
    "\n",
    "fuel_labeled = X_discretos['fuel-type'].map({'diesel': 0, 'gas': 1})\n",
    "aspiration_labeled = X_discretos['aspiration'].map({'std': 0, 'turbo': 1})\n",
    "engine_location_labeled = X_discretos['engine-location'].map({'front': 0, 'rear': 1})\n",
    "num_of_doors_labeled = X_discretos['num-of-doors'].map({'four': 4, 'two': 2})\n",
    "num_of_cylinders_labeled = X_discretos['num-of-cylinders'].map({'eight':8, 'five':5, 'four':4, 'six':6, 'three':3, 'twelve':12, 'two':2})\n",
    "\n",
    "matriz = np.stack([fuel_labeled,aspiration_labeled,engine_location_labeled,num_of_doors_labeled,num_of_cylinders_labeled],axis=1)\n",
    "X_label= pd.DataFrame(matriz,columns=['fuel-type','aspiration','engine-location','num-of-doors','num-of-cylinders'])\n",
    "X_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST: del label_encoding de los atributos binarios y ordinales\n",
    "for atributo in ['fuel-type', 'aspiration', 'engine-location', 'num-of-doors', 'num-of-cylinders']:\n",
    "    print(list(X_discretos[atributo].head(10)))\n",
    "    print(list(X_label[atributo].head(10)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: Evaluación de la contribución de cada atributo codificado con respecto al baseline de atributos numéricos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Codificación _one hot_ <a name=\"one_hot\"> </a>\n",
    "\n",
    "La codificación _one hot_ da lugar (para un atributo discreto) a tantas columnas como valores distintos tenga el atributo. Hay varias alternativas para realizar esta codificación (Pandas, Sklearn, Patsy, ...). Nosotros usaremos Pandas porque su sintaxis es muy sencilla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: codificar mediante one hot encoding los atributos categóricos\n",
    "#    - Pandas proporciona un método para hacerlo\n",
    "X_one_hot = pd.get_dummies(X_discretos,columns=['make', 'body-style', 'drive-wheels', 'engine-type', 'fuel-system'])\n",
    "X_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST: de la codificación one hot\n",
    "print(list(X_discretos['make'].head(10)))\n",
    "print(list(X_one_hot['make_audi'].head(10)))\n",
    "print(X_one_hot.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: crear una función 'filtra_columnas' que seleccione solo las columnas correspondientes a un grupo de atributos\n",
    "    ''' Construye un dataset solo con las columnas 'one hot' correspondientes al conjunto de atributos indicado\n",
    "    \n",
    "    Recibe:\n",
    "       - datos_one_hot: dataset con columnas codificadas mediante one hot\n",
    "       - atributos: nombres originales de los atributos a mantener\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST: de la función 'filtra_columnas'\n",
    "print(filtra_columnas(X_one_hot, ['make', 'body-style', 'fuel-system']).info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: Evaluación de la contribución de cada atributo codificado con respecto al baseline de atributos numéricos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Usando más atributos <a name=\"mas_atributos\"> </a>\n",
    "\n",
    "En esta última sección crearemos un dataset con los atributos numéricos, más la codificación de todos los atributos discretos. También haremos una prueba incluyendo un subconjunto de los atributos discretos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: crear un dataset 'X_eval' con los atributos numéricos, más todos los discretos codificados\n",
    "#    - Partir de los siguientes data frames: \n",
    "#         X_numericos\n",
    "#         X_label\n",
    "#         X_one_hot\n",
    "#    - Las listas de los nombres originales de los atributos codificados son:\n",
    "#         cols_label =  ['fuel-type', 'aspiration', 'engine-location', 'num-of-doors', 'num-of-cylinders']\n",
    "#         cols_one_hot = ['make', 'body-style', 'drive-wheels', 'engine-type', 'fuel-system']\n",
    "#    - En el caso de los atributos one hot hay que usar la función 'filtra_columnas' para seleccionar los atributos\n",
    "#    - Guardar dicho dataset en el fichero 'automobile-coded.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: evalua el regresor con el dataset de atributos numéricos y todos los discretos codificados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: crear un dataset 'X_eval' con los atributos numéricos, más todos los discretos codificados\n",
    "#         cols_label =  ['fuel-type', 'aspiration', 'engine-location', 'num-of-doors']\n",
    "#         cols_one_hot = ['make', 'body-style', 'fuel-system']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: evalua el regresor con el dataset de atributos numéricos y los mejores discretos codificados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados mejoran en ambos casos pero, curiosamente, con menos atributos se consiguen mejores resultados. Esto nos da pie a introducir la tarea que veremos en el siguiente notebook, la _selección de características_, que consiste en econtrar el subconjunto de atributos que mejor se comporta."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
